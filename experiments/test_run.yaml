version: 'v0'

experiment_name: 'test_run'

temporal_config:
  # duration for aggregating feature and labels for both trainig and testing
  feature_duration: '2 years'
  label_duration: '1 year'

  # start time for getting features
  # we assume that labels come immediately after features
  # this means that the training data comes in (fst, fst + fd)
  # testing data comes in (fst + fd, fst + fd + ld)
  feature_start_time: '2009-01-01'

  # interval and number of times to roll forward training and testing data
  # for cross validating on different train and test set combinations
  # this means that the above two intervals are going to be repeated
  # to generate num_train_repeat (train, test) splits
  train_repeat_interval: '1 year'
  num_train_repeat: 1

cohort_config:
  # query to obtain the entities for a train-test split
  # as_of_date is a placeholder set to the last date of the split
  query: |
    select distinct entity_id
    from semantic.events
    where event_date <= '{as_of_date}'::date
    order by entity_id

label_config:
  query: |
    select entity_id, max(label) as label
    from semantic.labels
    where event_date >= 'start_date' and event_date <= 'end_date'
    group by entity_id
    order by entity_id 
  name: 'penalized'

features:
  -
    prefix: 'reporting'
    from_table: 'semantic.reporting'
    table_type: 'entity'
    imputation: 'zero_noflag'
  -
    prefix: 'events'
    from_table: 'semantic.events'
    table_type: 'event'
    date_column_name: 'event_date'

    imputation:
      count: 'zero'
      sum: 'mean_noflag'

    aggregates:
      -
        column_name: 'found_violation'
        metrics:
          - 'count'
      -
        column_name: 'penalty_amount'
        metrics:
          - 'count'
          - 'sum'

grid_config:
  'sklearn.tree.DecisionTreeClassifier':
    max_depth: [1,5]
    max_features: [~, 'sqrt']
    min_samples_split: [1]
    criterion: ['gini']

scoring:
  sort_seed: 0
  testing_metric_groups:
    -
      metrics: ['precision@', 'recall@']
      thresholds:
        percentiles: [1.0]
  training_metric_groups:
    -
      metrics: [accuracy]
    -
      metrics: ['precision@', 'recall@']
      thresholds:
        percentiles: [1.0]
